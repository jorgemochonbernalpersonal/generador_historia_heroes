# Instrucciones para el Profesor

## üöÄ GU√çA R√ÅPIDA: Configurar IA en 3 minutos

### Opci√≥n m√°s f√°cil: Groq (Gratis y r√°pido) ‚≠ê RECOMENDADO

1. **Crear cuenta en Groq:**
   - Ve a: https://console.groq.com/
   - Crea una cuenta (gratis, no requiere tarjeta)
   - Ve a "API Keys" y crea una nueva clave
   - Copia la clave (empieza con `gsk_...`)

2. **Instalar las librer√≠as:**
   ```bash
   pip install groq python-dotenv
   ```

3. **Configurar el archivo .env (m√°s seguro):**
   - Copia el archivo `env.example` y ren√≥mbralo a `.env`
   - O crea un archivo nuevo llamado `.env` en la carpeta del proyecto
   - Abre el archivo `.env` y escribe:
     ```
     GROQ_API_KEY=tu_clave_aqui
     ```
   - Reemplaza `tu_clave_aqui` con tu clave real de Groq

4. **¬°Listo!** Ejecuta el programa:
   ```bash
   python generador_superheroes.py
   ```
   - Elige la opci√≥n 2, 3 o 4 del men√∫ para probar la IA real
   - Opci√≥n 2: Un superh√©roe con IA
   - Opci√≥n 3: Varios superh√©roes autom√°ticamente con IA
   - Opci√≥n 4: Superh√©roes aleatorios con IA

**Nota:** El archivo `.env` no se sube a Git (est√° protegido), as√≠ que tu clave est√° segura.

---

## Configuraci√≥n de la funci√≥n de IA

**IMPORTANTE:** El programa ya est√° configurado para usar **Groq** autom√°ticamente. Solo necesitas crear el archivo `.env` con tu API key de Groq (ver gu√≠a r√°pida arriba). **NO necesitas modificar el c√≥digo.**

**Si quieres usar otra API (OpenAI, Hugging Face, etc.):**
- Debes modificar la funci√≥n `pedir_a_la_ia()` en `generador_superheroes.py`
- Ver secci√≥n "C√ìDIGOS PARA CONFIGURAR" m√°s abajo
- Puedes leer la API key del archivo `.env` usando `os.getenv("NOMBRE_DE_LA_VARIABLE")`

## üÜì OPCIONES GRATUITAS PARA PROBAR

### Opci√≥n 1: OpenAI (Cr√©ditos gratuitos iniciales) ‚≠ê RECOMENDADO

**Ventajas:**
- ‚úÖ $5 USD de cr√©dito gratuito al registrarte
- ‚úÖ F√°cil de usar
- ‚úÖ Buena calidad

**Pasos:**
1. Ve a https://platform.openai.com/
2. Crea una cuenta (necesitas tarjeta, pero no se cobra si solo usas cr√©ditos gratuitos)
3. Ve a "API Keys" y crea una nueva clave
4. Instala: `pip install openai`
5. Usa el c√≥digo de abajo

### Opci√≥n 2: Hugging Face (Completamente gratis) üéÅ

**Ventajas:**
- ‚úÖ 100% gratis
- ‚úÖ No requiere tarjeta
- ‚úÖ Funciona bien para pruebas

**Pasos:**
1. Ve a https://huggingface.co/ y crea cuenta
2. Ve a https://huggingface.co/settings/tokens y crea un token
3. Instala: `pip install transformers requests`
4. Usa el c√≥digo de abajo

### Opci√≥n 3: Groq (Muy r√°pido y gratis) ‚ö°

**Ventajas:**
- ‚úÖ API gratuita con l√≠mites generosos
- ‚úÖ Muy r√°pido
- ‚úÖ No requiere tarjeta

**Pasos:**
1. Ve a https://console.groq.com/
2. Crea una cuenta
3. Crea una API key
4. Instala: `pip install groq`
5. Usa el c√≥digo de abajo

### Opci√≥n 4: Usar el modo demo (sin API real)

El c√≥digo actual funciona en modo demo sin necesidad de API. Los ni√±os pueden probar el programa y ver c√≥mo funciona, aunque las historias ser√°n de ejemplo.

---

## C√ìDIGOS PARA CONFIGURAR

### Opci√≥n 1: Usando OpenAI (ChatGPT) - Con cr√©ditos gratuitos

**Paso 1:** A√±ade tu API key al archivo `.env`:
```
OPENAI_API_KEY=tu_clave_openai_aqui
```

**Paso 2:** Modifica la funci√≥n `pedir_a_la_ia()` en `generador_superheroes.py`:

```python
from openai import OpenAI
import os
from dotenv import load_dotenv

load_dotenv()  # Cargar variables del .env

def pedir_a_la_ia(mensaje):
    # Leer API key del archivo .env
    API_KEY_OPENAI = os.getenv("OPENAI_API_KEY")
    
    if not API_KEY_OPENAI:
        # Si no est√° configurada, usar modo demo
        return "Historia de ejemplo..."
    
    client = OpenAI(api_key=API_KEY_OPENAI)
    
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",  # Modelo econ√≥mico
        messages=[
            {"role": "system", "content": "Eres un escritor creativo que crea historias de superh√©roes para ni√±os de 10 a√±os. Las historias deben ser cortas (3-4 p√°rrafos), emocionantes y apropiadas para ni√±os."},
            {"role": "user", "content": mensaje}
        ],
        max_tokens=300,
        temperature=0.8
    )
    
    return response.choices[0].message.content
```

**Instalaci√≥n:**
```bash
pip install openai
```

### Opci√≥n 2: Usando Hugging Face (100% gratis)

**Paso 1:** A√±ade tu token al archivo `.env`:
```
HUGGINGFACE_API_KEY=tu_token_huggingface_aqui
```

**Paso 2:** Modifica la funci√≥n `pedir_a_la_ia()` en `generador_superheroes.py`:

```python
import requests
import os
from dotenv import load_dotenv

load_dotenv()  # Cargar variables del .env

def pedir_a_la_ia(mensaje):
    # Leer token del archivo .env
    API_TOKEN = os.getenv("HUGGINGFACE_API_KEY")
    
    if not API_TOKEN:
        # Si no est√° configurada, usar modo demo
        return "Historia de ejemplo..."
    API_URL = "https://api-inference.huggingface.co/models/microsoft/DialoGPT-medium"
    
    headers = {"Authorization": f"Bearer {API_TOKEN}"}
    
    # Usar un modelo de texto m√°s adecuado
    API_URL = "https://api-inference.huggingface.co/models/gpt2"
    
    response = requests.post(API_URL, headers=headers, json={
        "inputs": f"Escribe una historia corta sobre un superh√©roe. {mensaje}",
        "parameters": {"max_length": 200, "temperature": 0.8}
    })
    
    if response.status_code == 200:
        resultado = response.json()
        if isinstance(resultado, list) and len(resultado) > 0:
            return resultado[0].get("generated_text", "Historia generada")
    else:
        # Si falla, devolver mensaje de ejemplo
        return f"Historia de ejemplo generada para: {mensaje[:50]}..."
    
    return "No se pudo generar la historia en este momento."
```

**Instalaci√≥n:**
```bash
pip install requests
```

**Nota:** Hugging Face puede tener l√≠mites de velocidad. Si falla, el programa usar√° un mensaje de ejemplo.

### Opci√≥n 3: Usando Groq (Gratis y r√°pido) ‚ö° - **YA CONFIGURADO**

**El c√≥digo actual ya est√° configurado para Groq.** Solo necesitas:

1. A√±ade tu API key al archivo `.env`:
   ```
   GROQ_API_KEY=tu_clave_groq_aqui
   ```

2. El c√≥digo ya lee autom√°ticamente del `.env` (no necesitas modificar nada)

**Si quieres ver c√≥mo funciona internamente:**

```python
from groq import Groq
import os
from dotenv import load_dotenv

load_dotenv()  # Cargar variables del .env

def pedir_a_la_ia(mensaje):
    # Leer API key del archivo .env
    API_KEY_GROQ = os.getenv("GROQ_API_KEY") or os.getenv("API_KEY_GROQ")
    
    if not API_KEY_GROQ:
        # Si no est√° configurada, usar modo demo
        return "Historia de ejemplo..."
    
    client = Groq(api_key=API_KEY_GROQ)
    
    response = client.chat.completions.create(
        model="llama-3.1-8b-instant",  # Modelo r√°pido y gratuito
        messages=[
            {"role": "system", "content": "Eres un escritor creativo que crea historias de superh√©roes para ni√±os de 10 a√±os. Las historias deben ser cortas (3-4 p√°rrafos), emocionantes y apropiadas para ni√±os."},
            {"role": "user", "content": mensaje}
        ],
        max_tokens=300,
        temperature=0.8
    )
    
    return response.choices[0].message.content
```

**Instalaci√≥n:**
```bash
pip install groq
```

### Opci√≥n 4: Usando Anthropic (Claude) - Opci√≥n de pago

```python
import anthropic

def pedir_a_la_ia(mensaje):
    client = anthropic.Anthropic(api_key="TU_API_KEY_AQUI")
    
    message = client.messages.create(
        model="claude-3-haiku-20240307",  # versi√≥n m√°s econ√≥mica
        max_tokens=300,
        messages=[
            {"role": "user", "content": mensaje}
        ]
    )
    
    return message.content[0].text
```

## üìã RECOMENDACIONES POR CASO DE USO

### Para probar r√°pido (sin registro):
- ‚úÖ **Modo Demo**: Ya funciona sin configuraci√≥n
- ‚úÖ **Groq**: Registro r√°pido, muy f√°cil

### Para uso educativo prolongado:
- ‚úÖ **OpenAI**: $5 gratis inicial, luego muy econ√≥mico (gpt-3.5-turbo cuesta ~$0.001 por historia)
- ‚úÖ **Groq**: Gratis con l√≠mites generosos

### Para uso completamente gratis:
- ‚úÖ **Hugging Face**: 100% gratis, pero puede ser m√°s lento
- ‚úÖ **Modo Demo**: Funciona perfectamente para ense√±ar el concepto

## Instalaci√≥n de dependencias

Dependiendo de la opci√≥n que elijas:

```bash
# Para OpenAI
pip install openai

# Para Groq
pip install groq

# Para Hugging Face
pip install requests

# Para Anthropic (opci√≥n de pago)
pip install anthropic
```

## üìù C√≥mo funciona el archivo .env

El archivo `.env` es la forma m√°s segura de guardar tus API keys. **NO se sube a Git** (est√° protegido).

### Estructura del archivo .env:

```
# Para Groq (ya configurado en el c√≥digo)
GROQ_API_KEY=tu_clave_groq_aqui

# Para OpenAI (requiere modificar c√≥digo)
OPENAI_API_KEY=tu_clave_openai_aqui

# Para Hugging Face (requiere modificar c√≥digo)
HUGGINGFACE_API_KEY=tu_token_huggingface_aqui
```

### C√≥mo leer del .env en Python:

```python
import os
from dotenv import load_dotenv

# Cargar variables del archivo .env
load_dotenv()

# Leer una variable espec√≠fica
api_key = os.getenv("GROQ_API_KEY")  # Lee GROQ_API_KEY del .env
```

### Alternativa: Variables de entorno del sistema

Tambi√©n puedes configurar variables de entorno del sistema (menos recomendado para este proyecto):

**Windows (PowerShell):**
```powershell
$env:GROQ_API_KEY="tu_clave_aqui"
```

**Linux/Mac:**
```bash
export GROQ_API_KEY="tu_clave_aqui"
```

## Uso en clase

1. **Primera sesi√≥n**: Ejecuta el programa en modo demo (sin API) para que los ni√±os vean c√≥mo funciona.

2. **Segunda sesi√≥n**: Si tienes acceso a una API, configura la funci√≥n y deja que los ni√±os usen la versi√≥n real.

3. **Enfoque progresivo**:
   - Empieza con Nivel 1 (sin IA)
   - Luego Nivel 2 (un superh√©roe con IA)
   - Finalmente Nivel 2 Avanzado (varios superh√©roes autom√°ticamente)

## Personalizaci√≥n

Puedes modificar:
- La lista de superh√©roes en `crear_varios_superheroes()`
- Las preguntas que se hacen al usuario
- El formato de salida
- Los mensajes de la interfaz

## Notas importantes

- **Costos**: Si usas una API de pago, ten en cuenta los costos por llamada. Para ni√±os, usa modelos m√°s econ√≥micos (gpt-3.5-turbo o claude-haiku).
- **L√≠mites de velocidad**: Algunas APIs tienen l√≠mites de velocidad. Para procesar varios superh√©roes, considera a√±adir un peque√±o delay entre llamadas.
- **Errores**: A√±ade manejo de errores b√°sico para que si falla la API, el programa no se rompa completamente.
